{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334f6137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Mask R-CNN model...\n",
      "[INFO] making predictions with Mask R-CNN...\n",
      "Processing 1 images\n",
      "image                    shape: (284, 512, 3)         min:    0.00000  max:  252.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  141.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "[[587, 1251, 727, 1582], [481, 341, 597, 446], [464, 1191, 548, 1328], [548, 1634, 664, 1778], [467, 7, 562, 112], [460, 1332, 527, 1451], [534, 1388, 590, 1518], [495, 516, 653, 769], [488, 1680, 566, 1778]]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# import the necessary packages\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "import colorsys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "\n",
    "ap.add_argument(\"-w\", \"--whichone\", type=str, default=None, help=\"path to input video file\")\n",
    "ap.add_argument(\"-i\", \"--input\", type=str, default=None, help=\"path to input video file\")\n",
    "ap.add_argument('-f', \"--folder\", type=str, default=None, help=\"path to input video folder\")\n",
    "ap.add_argument(\"-o\", \"--output\", type=str, default=\"./output\", help=\"path to output images folder\")\n",
    "ap.add_argument(\"-s\", \"--source\", type=str, default=\"./source\", help=\"path to save sorce video to image folder\")\n",
    "ap.add_argument(\"-c\", \"--csvfolder\", type=str, default=\"./csvfiles\", help=\"path to output csv files folder\")\n",
    "ap.add_argument(\"-e\", \"--extendsion\", type=str, default=\"mp4\", help=\"video extendsion file\")\n",
    "ap.add_argument(\"--fps\", type=int, default=30, help=\"count video to image per frame\")\n",
    "ap.add_argument(\"-r\", \"--result\", type=int, default=1, help='whether storage source and result image')\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# ===== 改這裡就好 ====\n",
    "which_one = \"sheep\" # 固定寫死。人 : \"person\"； 車 : \"car\" ； 巴士 : \"bus\" ；羊 : \"sheep\"\n",
    "#which_one = args[\"whichone\"] # python Class_Identification.py -w person\n",
    "# 可以變成參數\n",
    "# python Class_Identification.py -w person\n",
    "# python Class_Identification.py -w car\n",
    "# python Class_Identification.py -w bus\n",
    "# python Class_Identification.py -w sheep\n",
    "# ===== 改這裡就好 ====\n",
    "\n",
    "#Project: current directory\n",
    "pathProject = os.getcwd()\n",
    "pathLib     = os.path.sep.join([pathProject,\"lib\"])\n",
    "#testing dataset\n",
    "videoPath = args[\"input\"]\n",
    "videoFolder = args[\"folder\"]\n",
    "inputPath   = args[\"input\"]\n",
    "csvfolder = args[\"csvfolder\"]\n",
    "fps = args['fps']\n",
    "outputPath  = args[\"output\"]\n",
    "if args['result'] == 1:\n",
    "    save = True\n",
    "else:\n",
    "    save = False\n",
    "sorucePath = args['source']\n",
    "labelsPath  = os.path.sep.join([pathLib, \"coco_labels.txt\"])\n",
    "weightsPath = os.path.sep.join([pathLib, \"mask_rcnn_coco.h5\"])\n",
    "\n",
    "color={\"red\":(0,0,255),\"green\":(0,255,0),\"blue\":(255,0,0),\n",
    "       \"yellow\":(0,255,255),\"cyan\":(255,255,0)} #BGR\n",
    "\n",
    "# load the class label names from disk, one label per line\n",
    "CLASS_NAMES = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "# generate random (but visually distinct) colors for each class label\n",
    "# (thanks to Matterport Mask R-CNN for the method!)\n",
    "hsv = [(i / len(CLASS_NAMES), 1, 1.0) for i in range(len(CLASS_NAMES))]\n",
    "COLORS = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "random.seed(42)\n",
    "random.shuffle(COLORS)\n",
    "\n",
    "class SimpleConfig(Config):\n",
    "    # give the configuration a recognizable name\n",
    "    NAME = \"coco_inference\"\n",
    "    # set the number of GPUs to use along with the number of images per GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # number of classes (we would normally add +1 for the background\n",
    "    # but the background class is *already* included in the class names)\n",
    "    NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# initialize the inference configuration\n",
    "config = SimpleConfig()\n",
    "\n",
    "# initialize the Mask R-CNN model for inference and then load the weights\n",
    "print(\"[INFO] loading Mask R-CNN model...\")\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config,\tmodel_dir=os.getcwd())\n",
    "model.load_weights(weightsPath, by_name=True)\n",
    "\n",
    "dataSource = \"./my_images/\" + which_one + \".jpg\"\n",
    "\n",
    "which_one_result = which_one+\"_result.jpg\"\n",
    "img = cv2.imread(dataSource)\n",
    "img = cv2.resize(img, (1800, 1000), interpolation=cv2.INTER_AREA)\n",
    "overlay = img.copy()\n",
    "\n",
    "def mask_rcnn(image, convertSize, showName=False, showNumberOfPerson=False):\n",
    "    img = image.copy()\n",
    "    # perform a forward pass of the network to obtain the results\n",
    "    print(\"[INFO] making predictions with Mask R-CNN...\")\n",
    "    color = (0,255,0) #BGR\n",
    "    width_img   = img.shape[1] #x\n",
    "    ratio = convertSize/width_img\n",
    "    img = imutils.resize(img, width=convertSize)\n",
    "    \n",
    "    #detect results   \n",
    "    r = model.detect([img], verbose=1)[0]\n",
    "    \n",
    "    #convert the image back to BGR so we can use OpenCV's drawing functions\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    count  = 0 #count people\n",
    "    bboxes = [] #boxes in image\n",
    "    #loop over the predicted scores and class labels\n",
    "    for i in range(0, len(r[\"scores\"])):\n",
    "    #extract the bounding box information, class ID, label, predicted probability, and visualization color\n",
    "        classID = r[\"class_ids\"][i]\n",
    "        label   = CLASS_NAMES[classID]\n",
    "        if label != which_one: #check person class car\n",
    "            continue\n",
    "        \n",
    "        count  = count + 1\n",
    "        (startY, startX, endY, endX) = r[\"rois\"][i] #get bbox\n",
    "        #covert to original codinate\n",
    "        startY = int(startY/ratio)\n",
    "        startX = int(startX/ratio)\n",
    "        endY   = int(endY/ratio)\n",
    "        endX   = int(endX/ratio)\n",
    "        bbox = [startY, startX, endY, endX]\n",
    "        bboxes.append(bbox)\n",
    "        img = imutils.resize(img, width=width_img) #covert image to orginal size\n",
    "        \n",
    "        #draw the bounding box\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), color, 2)\n",
    "        #show class label, and score of the object\n",
    "        if showName:\n",
    "            #score = r[\"scores\"][i]\n",
    "            #text = \"{}: {:.3f}\".format(label, score)\n",
    "            text =\"#\"+str(count)\n",
    "            y    = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.putText(img, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "      #Total of boxs\n",
    "    if showNumberOfPerson:\n",
    "        cv2.putText(img, str(len(bboxes)),(10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 2)\n",
    "            \n",
    "    return img, bboxes\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "bb=[]\n",
    "widthMask= 512 #image size for Mask RCNN\n",
    "\n",
    "crop_img,bb = mask_rcnn(img, widthMask)\n",
    "\n",
    "#cv2.imwrite('crop_img.jpg', crop_img)\n",
    "print(bb)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "num = 0\n",
    "for i in range(len(bb)):\n",
    "    num += 1\n",
    "print(num)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "text = \"which_one Counting : \" + which_one + \" \" + str(num)\n",
    "cv2.putText(crop_img, text, (10, 40), cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "cv2.imwrite(which_one_result, crop_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d08c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
